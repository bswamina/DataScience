---
title: 'Relationship Between Miles Per Gallon and Transmission (Automatic vs Manual)'
author: 'Bhaskar S'
date: '08th Jun 2016'
output:
  pdf_document: default
  html_document:
    keep_md: yes
---

## __Executive Summary__
In this project, we look at the __mtcars__ dataset to explore the relationship between a set of variables and miles per gallon (MPG) (outcome). In particularly, we are interested in answering the following two questions:

* _Is an automatic or manual transmission better for MPG_
* _Quantify the MPG difference between automatic and manual transmissions_

Using Exploratory Data Analysis, Hypothesis Testing, and Linear Regression Modelling, we can conclude that the cars with Manual Transmission provide a better MPG compared to the cars with Automatic Transmission.

## __Setup__
For this analysis, we will be using the R packages `ggplot2` and `GGally`. We load the desired libraries and the __mtcars__ dataset:

```{r setup_1, echo = TRUE}
library(ggplot2); library(GGally); data('mtcars')
```

## __Exploratory Data Analysis__
We will display the dimensions and the structure __mtcars__:

```{r display_1, echo = TRUE, results = 'hide'}
str(mtcars)
```

From __Output.1__ in __APPENDIX__, we see there are __32__ rows and __11__ columns and all the columns are `numeric`. Now, we compute and display the _mean_ mpg for automatic (`am` = 0) and manual (`am` = 1):

```{r display_2, echo = TRUE, results = 'hide'}
aggregate(mpg ~ am, data=mtcars, mean)
```

From __Output.2__ in __APPENDIX__, we observe that the _mean_ mpg for automatic is about `17` and that for manual is about `24`. The __Plot 1__ in __APPENDIX__ also illustrates and confirms this fact.

The initial assessment indicates that the __mpg__ from manual is better compared to automatic.

## __Hypothesis Testing__
We collect the `mpg` values for automatic (`am` = 0) and manual (`am` = 1) into vectors _auto_ and _manual_ respectively and display their lengths:

```{r display_3, echo = TRUE, results = 'hide'}
auto <- mtcars[mtcars$am==0, 'mpg']; length(auto)
manual <- mtcars[mtcars$am==1, 'mpg']; length(manual)
```

From the above, we see the lengths are less than __30__. Also, we do not have any knowledge of their population variances. As a result, we will be conducting a __t__ hypothesis test to find the __p-value__. We will test the _null_ hypothesis that the mean `mpg` for automatic and manual are equal with a 95% __Confidence Interval__. Since the _null_ hypothesis is testing for equality, this is a __two-tail__ test. If the __p-value__ is < 0.05, we reject the _null_ hypothesis.

The following code performs a two-tailed __t__ hypothesis test:

```{r compute_1, echo = TRUE, results = 'hide'}
t.test(auto, manual, var.equal = FALSE, paired = FALSE, conf.level = 0.95)
```

From __Output.3__ in __APPENDIX__, we observe a __p-value__ of __0.0014__ that is less than __0.05__ and hence we reject the _null_ hypothesis concluding that there is a major difference between the mean `mpg` for manual vs automatic.

## __Linear Regression Modelling__
We start with the `pairs` plot. From __Plot.2__ in __APPENDIX__, we observe that the variables `cyl` (-0.852), `disp` (-0.848), and `wt` (0.868) are highly correlated to `mpg`. We will create few models with `mpg` as the outcome and `am`, `cyl`, `disp`, and `wt` as explanatory variables:

```{r compute_2, echo = TRUE, results = 'hide'}
fit1 <- lm(mpg ~ ., data=mtcars)
fit2 <- lm(mpg ~ am, data=mtcars)
fit3 <- lm(mpg ~ am+cyl, data=mtcars)
fit4 <- lm(mpg ~ am+cyl+disp, data=mtcars)
fit5 <- lm(mpg ~ am+cyl+disp+wt, data=mtcars)
```

To compare the various models, we perform an _ANOVA_ analysis on the models:

```{r compute_3, echo = TRUE, results = 'hide'}
anova(fit1, fit2, fit3, fit4, fit5)
```

From __Output.4__ in __APPENDIX__, we observe that models _fit2_ and _fit3_ have lower __p-values__ and hence are better choices.

To pick the best model, we compare the `R-Squared` values for the models _fit2_ and _fit3_ and pick the one with a larger value:

```{r compute_4, echo = TRUE, results = 'hide'}
summary(fit2)$r.squared; summary(fit3)$r.squared
```

From __Output.5__ in __APPENDIX__, we choose model _fit3_ as it has a larger `R-Squared` value.

Finally, we look at the residual plots:

```{r display_4, eval=FALSE, include=FALSE, results='hide'}
par(mfrow=c(1,2)); plot(fit3, which=c(1,2))
```

From __Plot.3__ in __APPENDIX__, we infer that the residuals are randomly scattered and follow a normal distribution.

Now that we have the best model, we look at the coefficients for the model _fit3_:

```{r compute_5, echo = TRUE, results = 'hide'}
summary(fit3)$coef
```

From __Output.6__ in __APPENDIX__, we conclude that the _mean_ `mpg` for manual is `2.567` more than for automatic.
<br/>
\newpage

# __APPENDIX__

### __Output.1__
```{r output_1, echo = FALSE}
str(mtcars)
```

### __Output.2__
```{r output_2, echo = FALSE}
aggregate(mpg ~ am, data=mtcars, mean)
```

### __Plot.1__
```{r plot_1, echo = FALSE, fig.path = './figures/', warning = FALSE, message = FALSE}
ggplot(mtcars, aes(x=am, y=mpg, fill=as.factor(am))) + geom_boxplot() + theme_bw()
```

### __Output.3__
```{r output_3, echo = FALSE}
t.test(auto, manual, var.equal = FALSE, paired = FALSE, conf.level = 0.95)
```

### __Plot.2__
```{r plot_2, echo = FALSE, fig.path = './figures/', warning = FALSE, message = FALSE}
ggpairs_wrapper <- function(data, mapping, color='blue', method='loess', ...){
    p <- ggplot(data=data, mapping=mapping) + 
        geom_point(color=color) +
        geom_smooth(method=method, color='red', ...) +
        theme_bw() +
        theme(axis.ticks.x=element_blank(), axis.ticks.y=element_blank(),
              axis.text.x=element_blank(), axis.text.y=element_blank())
    p
}
ggpairs(mtcars, lower=list(continuous=ggpairs_wrapper), diag='blank')
```

### __Output.4__
```{r output_4, echo = FALSE}
anova(fit1, fit2, fit3, fit4, fit5)
```

### __Output.5__
```{r output_5, echo = FALSE}
summary(fit2)$r.squared; summary(fit3)$r.squared
```

### __Plot.3__
```{r plot_3, echo = FALSE, fig.path = './figures/', warning = FALSE, message = FALSE}
par(mfrow=c(1,2)); plot(fit3, which=c(1,2));par(mfrow=c(1,1))
```

### __Output.6__
```{r output_6, echo = FALSE}
summary(fit3)$coef
```

